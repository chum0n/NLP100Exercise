# 第４章：形態素解析に関するメモ

## 形態素解析とは

> 形態素解析とは、文法的な情報の注記の無い自然言語のテキストデータ（文）から、対象言語の文法や、辞書と呼ばれる単語の品詞等の情報にもとづき、形態素（おおまかにいえば、言語で意味を持つ最小単位）の列に分割し、それぞれの形態素の品詞等を判別する作業

もう少し簡単にいうと、、
形態素解析とは、私たちが普段生活の中で一般的に使っている言葉、つまり「自然言語」を形態素にまで分割する技術のこと

形態素とは、言葉が意味を持つまとまりの単語の最小単位のこと

ex.「私は台所で料理します」  
「私(代名詞)/は（副助詞）/台所(名詞)/で(助詞)/料理（名詞）/し(動詞)/ます（助動詞）」

参考にしたサイト  
[素人の言語処理100本ノック:まとめ](https://qiita.com/segavvy/items/fb50ba8097d59475f760)  
[言語処理100本ノックでPythonに入門](https://qiita.com/hi-asano/items/02d82cc1e89fc663b4e6)  
[u++の備忘録](https://upura.hatenablog.com/entry/2020/04/14/024948)  

## 30. 形態素解析結果の読み込み

`形態素解析結果（neko.txt.mecab）を読み込むプログラムを実装せよ．ただし，各形態素は表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をキーとするマッピング型に格納し，1文を形態素（マッピング型）のリストとして表現せよ．第4章の残りの問題では，ここで作ったプログラムを活用せよ．`

MeCabについて

- オープンソースの日本語の形態素解析エンジン
- 言語や辞書、またデータベース化された言語資料であるコーパスに依存しない、汎用的な設計がMeCabの特徴
- ちなみに、名前の由来は「和布蕪(めかぶ)」から来ている
- MeCabで使用できる言語はC、C＃、C＋＋、Java、Perl、Python、Ruby、Rとたくさんある
- さまざまな辞書と連結させることもできるため、日本語の形態素解析エンジンの中では最も良く使われている

MeCabのインストール
[Python3でMeCabを使う方法を現役エンジニアが解説【初心者向け】 | TechAcademyマガジン](https://techacademy.jp/magazine/24037)←これいまいち
[Python3からMeCabを使う](https://qiita.com/taroc/items/b9afd914432da08dafc8)

ファイルに対して形態素解析を実行
```
mecab < section4/neko.txt > section4/neko.txt.mecab
```

### *1
MeCab::Tagger というクラスのインスタンスを生成し、parse (もしくは parseToString) というメソッドを呼ぶことで、解析結果が文字列として取得できる。MeCab::Tagger のコンストラクタの引数は、基本的に mecab の実行形式に与えるパラメータと同一で、それらを文字列として与える。([スクリプト言語のバインディング](https://taku910.github.io/mecab/bindings.html)より)

```
# 通常の実行結果
$ echo "インスタ映え" | mecab
インスタ    名詞,一般,*,*,*,*,*
映え  名詞,一般,*,*,*,*,映え,ハエ,ハエ
EOS
# neologdによる実行結果
$ echo "インスタ映え" | mecab -d /usr/local/mecab/lib/mecab/dic/mecab-ipadic-neologd
インスタ映え  名詞,固有名詞,一般,*,*,*,インスタ映え,インスタハエ,インスタハエ
EOS

他には
echo "インスタ映え" | mecab -Owakati
```

### *2

generator(ジェネレータ)  
generator iterator を返す関数です。 通常の関数に似ていますが、 yield 式を持つ点で異なります。 yield 式は、 for ループで使用できたり、next() 関数で値を 1 つずつ取り出したりできる、値の並びを生成するのに使用されます。

通常はジェネレータ関数を指しますが、文脈によっては ジェネレータイテレータ を指す場合があります。 意図された意味が明らかでない場合、 明瞭化のために完全な単語を使用します。

[Pythonのジェネレーターってなんのためにあるのかをなるべく分かりやすく説明しようと試みた](https://qiita.com/keitakurita/items/5a31b902db6adfa45a70)←めっちゃわかりやすい

超簡単な説明
- 通常の関数の、return文をyieldに置き換えたもの
- returnの代わりにyieldと書くと、呼び出しただけでは値を返さなくなる代わりに、for文などで呼び出すと順々に値を返すようになる。
- ジェネレーターは関数よりも、圧倒的にクラスに近いもの
- ジェネレーターは呼び出されるたびに、行われた処理を記憶する。つまり、ステートをもつ。
- ジェネレーターが活躍する場面は、順々に値を返し、ステートを持つ必要があるが、リスト全体を保持する必要がない場面(リスト全体をメモリ内に保持するのが難しい、かつ不要なとき)

ここでは、fix_mecab()はfor文内で1文の各形態素を辞書化したものをどんどん返しlinesはそれが集まったものという認識でいい。

### *3

形態素解析結果のフォーマットは、

```
表層形\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音
```

という形がデフォルト(本家の[MeCab: Yet Another Part-of-Speech and Morphological Analyzer](http://taku910.github.io/mecab/)より)

よってタブで分割することでcols[0]に表層形、cols[1]にそれ以外が入る。

### *4

cols[1]の中身はカンマでつながっているのでこれで分ける。

rest_colsの中身は  
rest_cols = [品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音]  
みたいな感じ

### *5

今回求められているのは`各形態素は表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をキーとするマッピング型に格納し，1文を形態素（マッピング型）のリストとして表現`すること。

表層形（surface）はcols[0]に，基本形（base）はrest_colsの中の6番目に，品詞（pos）はrest_colsの中の0番目に，品詞細分類1（pos1）はrest_colsの中の1番目にある。

### *6

実際の形をみると、句点は

```
。	記号,句点,*,*,*,*,。,。,。
```

となっている。品詞細分類1（pos1）が句点となっているのがわかる。

### メモ

今回のparse_txt関数とfix_mecab関数をmecabfunc.pyにまとめた。

## 31. 動詞

`動詞の表層形をすべて抽出せよ．`

### *1

出現する動詞には重複がたくさんあるのでsetを用いることでそれを回避する。ただし、出現順に格納していくリストも用意する(あとで使う)。

### *2

for文の二重構造の意味を説明する。

```
linesの中のlineは例えばこんなの
[{'surface': '名前', 'base': '名前', 'pos': '名詞', 'pos1': '一般'}, {'surface': 'は', 'base': 'は', 'pos': '助詞', 'pos1': '係助詞'}, {'surface': 'まだ', 'base': 'まだ', 'pos': '副詞', 'pos1': '助詞類接続'}, {'surface': '無い', 'base': '無い', 'pos': '形容詞', 'pos1': '自立'}, {'surface': '。', 'base': '。', 'pos': '記号', 'pos1': '句点'}]
すなわち、
[morpheme, morpheme, morpheme...]
みたいな感じ

lineの中のmorpheme一つは例えばこんなの
{'surface': '名前', 'base': '名前', 'pos': '名詞', 'pos1': '一般'}

これの'pos'が'動詞'のやつの'surface'を持ってきたらいい！
```

### *3

setを使うと出現順になってくれず見づらいのでリストを使ってソートする。

### メモ

出力結果をみると、「し」が上は一回の出力になっていることがわかる。

## 32. 動詞の原形

`動詞の原形をすべて抽出せよ．`

さっきのsurfaceをbaseに変えただけ

### *1

リスト内包表記を用いた。

extendメソッドは、リストに別のリストの要素を追加する時に使う。追加できるのはリストなどのイテラブルなオブジェクト。イテラブルなオブジェクトとは文字列やリスト、タプル、辞書など。

リスト内包表記の書き方は

```
[式 for 任意の変数名 in イテラブルオブジェクト if 条件式]
```
今回は一番外側の大カッコはあってもなくてもよかった。

## 33. 「AのB」
`2つの名詞が「の」で連結されている名詞句を抽出せよ．`

### *1

もう一度lineの形を確認すると、
```
linesの中のlineは例えばこんなの
[{'surface': '名前', 'base': '名前', 'pos': '名詞', 'pos1': '一般'}, {'surface': 'は', 'base': 'は', 'pos': '助詞', 'pos1': '係助詞'}, {'surface': 'まだ', 'base': 'まだ', 'pos': '副詞', 'pos1': '助詞類接続'}, {'surface': '無い', 'base': '無い', 'pos': '形容詞', 'pos1': '自立'}, {'surface': '。', 'base': '。', 'pos': '記号', 'pos1': '句点'}]
すなわち、
[morpheme, morpheme, morpheme...]
みたいな感じ
```

だった。今探すのは「i番目(ただしiは1番目からリストの長さ-1番目まで)が'の'」かつ「i-1番目が名詞」かつ「i+1番目が名詞のもの」

### メモ

出力に「本の上」があるとなしでわかる

## 34. 名詞の連接
`名詞の連接（連続して出現する名詞）を最長一致で抽出せよ．`

名詞がくるたびにnounsというリストに入れていく。名詞以外が来た時にnounsの長さが2以上かを判定し、2以上ならばそれを出現順で格納されるリストに入れていく。

### *1

Pythonで文字列リストを文字列に変換する方法

```
文字列 = ‘区切り文字’.join(リスト)
```

を用いている。

### メモ

出力の「勉強家」でわかる。

## 35. 単語の出現頻度Permalink
`文章中に出現する単語とその出現頻度を求め，出現頻度の高い順に並べよ．`

### *1


class collections.Counter([iterable-or-mapping])  
Counter はハッシュ可能なオブジェクトをカウントする dict のサブクラスです。これは、要素を辞書のキーとして保存し、そのカウントを辞書の値として保存するコレクションです。カウントは、0 や負のカウントを含む整数値をとれます。
([collections --- コンテナデータ型 — Python 3.8.3 ドキュメント](https://docs.python.org/ja/3/library/collections.html#collections.Counter)より)

要するに、(単語, 単語出現回数)みたいなのをいっぱい入れることができる。これを使う。

使うメソッドは以下の二つ

update([iterable-or-mapping])  
要素が iterable からカウントされるか、別の mapping (やカウンタ) が追加されます。

most_common()  
most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered


### *2

条件分岐がないという意味でさっきより簡単なリスト内包表記

```
[式 for 任意の変数名 in イテラブルオブジェクト]
```

## 36. 頻度上位10語
`出現頻度が高い10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．`

まずmatplotlibが入っていない場合はインストールする。

[pythonのmatplotlibの使い方をまとめてみた](https://qiita.com/renesisu727/items/24fc4cd8fa2635b00a0d)によるとmatplotlibには二つの流儀が存在し、全てのplt.なんとかで済ませるPyplotインターフェースと、figやaxを定義した後にax.plotで書くオブジェクト指向インターフェースがあるらしい。画像解析の時に全てのplt.なんとかで済ませる人だったので前者でいく。

使い方は「matplotlib 使い方」、「matplotlib 棒グラフ」で検索して出てきたいくつかのサイトで学習。

### *1
10語と指定されたのでこれを使う。

most_common([n])  
Return a list of the n most common elements and their counts from the most common to the least.

### *2

`print(commonwords_list)`の結果は

```
[('の', 9194), ('。', 7486), ('て', 6873), ('、', 6772), ('は', 6422), ('に', 6268), ('を', 6071), ('と', 5515), ('が', 5339), ('た', 3989)]
```
だが、これをグラフにするためには、x軸用の単語のリストとy軸用の出現数のリストに分ける必要がある。これにはzip関数を使った。なお、`zip(*commonwords_list)`という書き方は`zip(commonwords_list[0], commonwords_list[1], ...)`と等価。

### *3

棒グラフを書く最も基本的な形は
```
x = np.array([1, 2, 3, 4, 5])
y = np.array([100, 200, 300, 400, 500])
plt.bar(x, y)
```
みたいな感じ。これに色々加えていく。

### *4
日本語対応させる

matplotlibで何もやらず日本語書くと豆腐フォントになってしまう(1枚目)。日本語表示にするためにmatplotlibrcを書き換える方法などがあるが、面倒くさいのでより簡単な方法でやる。以下のサイトを参考にした。  
[【matplotlib日本語表示】matplotlibrcを書き換えずに日本語表示する](https://qiita.com/ysdyt/items/3eb9b438980409c8f3e2)

1. フォントをダウンロード。ダウンロードするフォントは「mac フリーフォント」で検索して出てきたものを使う。今回は以下のサイトからダウンロードしてきたものを使った。  
[フリーフォントやさしさゴシックのダウンロード | フォントな](http://www.fontna.com/blog/379/)
2. パス指定してプロパティ作る
3. fontpropertiesにそれを渡す。ここで困ったのがplt.barのなかで渡すとエラーになることだった(AttributeError: 'Rectangle' object has no property 'fontproperties')。日本語を用いるのはx軸のラベルだったので、plt.xticksにx軸ラベル情報として全部渡すとokになった。xticksはx軸の目盛り値の設定またはクエリ。  
[x 軸の目盛り値の設定またはクエリ - MATLAB xticks - MathWorks 日本](https://jp.mathworks.com/help/matlab/ref/xticks.html)

### *5

タイトルとラベルとグリッドを指定する。
タイトルもラベルも先ほどの感じでやれば日本語を使えるが、面倒だったので英語にした。

グリッドだが、最初はplt.grid(true)としていたがx軸にグリッド入るのが気持ち悪かったのでplt.grid(axis='y')に変更

### *6

1. pyplotをインポートする前にmatplotlib.use('Agg')を記述。
2. plt.savefig(figure.png')で画像ファイルとしてカウントディレクトリに保存。
以下のサイトを参考
[matplotlibで作成したプロットを画像ファイルに保存する方法](https://qiita.com/koichifukushima/items/e63e642431db92178188)

## 37. 「猫」と共起頻度の高い上位10語Permalink
`「猫」とよく共起する（共起頻度が高い)10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．`

共起するとは？  
共起の意味は` 複数の言語現象が同一の発話・文・文脈などの言語的環境において生起すること。「しとしと」は「雨が降る」とは共起するが、「雪が降る」とは共起しないといえる。`とあった。([共起(きょうき)とは何？ Weblio辞書](https://www.weblio.jp/content/共起)より)

猫が現れる文中の猫以外の言葉の出現回数をカウントしていったら良さそう。あとは36番と一緒。

### *1

表層形に「猫」が出てきたらその単語を含む文のなかで表層形が「猫」となっている形態素以外の形態素の基本形を取得してカウントする。カウントは一回でいいのでbreakする。

## 38. ヒストグラム
`単語の出現頻度のヒストグラムを描け．ただし，横軸は出現頻度を表し，1から単語の出現頻度の最大値までの線形目盛とする．縦軸はx軸で示される出現頻度となった単語の異なり数（種類数）である．`

ヒストグラムの書き方は以下のサイトで学習。  
[matplotlib でヒストグラムを描く – Python でデータサイエンス](https://pythondatascience.plavox.info/matplotlib/ヒストグラム)

あとはだいたいこれまでと同じ

### *1

ビンの数30とかにしてたが、だいたい25くらいまでだったので25にした。あと、出現頻度0を消したかったのでxlimで消した。

## 39. Zipfの法則
`単語の出現頻度順位を横軸，その出現頻度を縦軸として，両対数グラフをプロットせよ．`

Zipfの法則  
読み方はジップの法則あるいはジフの法則。出現頻度が k 番目に大きい要素が全体に占める割合が1/kに比例するという経験則。([ジップの法則 - Wikipedia](https://ja.wikipedia.org/wiki/ジップの法則)より)

### *1

今回は両対数グラフなので、範囲の調整はしていない。

### *2

はじめ、`range(1, len(counts))`としてしまっていた。すると`ValueError: x and y must have same first dimension, but have shapes (13589,) and (13590,)`と言われた。確かに数が異なっていたので1足した。

## 参考資料

[形態素解析 - Wikipedia](https://ja.wikipedia.org/wiki/形態素解析)
[形態素解析とは？おすすめの5大解析ツールや実際の応用例を紹介](https://udemy.benesse.co.jp/ai/morphological-analysis.html)